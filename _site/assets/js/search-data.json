{
  "0": {
    "id": "0",
    "title": "Intro PCL",
    "content": "PCL이란?  PCL에 대한 기본적인 개요 부분 작성 예정입니다.",
    "url": "http://localhost:4000/docs/200-intro-pcl",
    "relUrl": "/docs/200-intro-pcl"
  },
  "1": {
    "id": "1",
    "title": "Python PCL",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;python-pcl                      Python-PCL&amp;#182;본 챕터에서는 PCL의 Python버젼인 Python-PCL의 기본적인 파일 입력, Numpy변환, 저장 방법에 대하여 정리 하였습니다. In&amp;nbsp;[1]:    %load_ext watermark%watermark -d -v -p pcl,numpy        2018-11-22CPython 2.7.12IPython 5.8.0pcl unknownnumpy 1.15.4In&amp;nbsp;[1]:    import pclimport numpy as npimport osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)    Point cloud &amp;#49373;&amp;#49457;&amp;#182;&amp;#48176;&amp;#50676;&amp;#47196; &amp;#49373;&amp;#49457;&amp;#182;In&amp;nbsp;[3]:    pc_array = np.array([[1, 2, 3], [3, 4, 5]], dtype=np.float32)print(pc_array)        [[1. 2. 3.] [3. 4. 5.]]In&amp;nbsp;[4]:    #방법 1pc = pcl.PointCloud(pc_array)print(pc)        &amp;lt;PointCloud of 2 points&amp;gt;In&amp;nbsp;[5]:    #방법 2pc = pcl.PointCloud()pc.from_array(pc_array)print(pc)        &amp;lt;PointCloud of 2 points&amp;gt;PCD &amp;#54028;&amp;#51068; &amp;#51069;&amp;#44592;&amp;#182;In&amp;nbsp;[8]:    pc = pcl.load(&amp;quot;./sample/lobby.pcd&amp;quot;) # &amp;quot;pc.from_file&amp;quot; Deprecatedprint(pc)        &amp;lt;PointCloud of 19329 points&amp;gt;&amp;#51221;&amp;#48372; &amp;#54869;&amp;#51064;&amp;#182;In&amp;nbsp;[8]:    print(&amp;quot;포인트 수 : {}&amp;quot;.format(pc.size))        포인트 수 : 19329In&amp;nbsp;[10]:    print (&amp;#39;Loaded &amp;#39; + str(pc.width * pc.height) + &amp;#39; data points from test_pcd.pcd with the following fields: &amp;#39;)for i in range(0, 10):#pc.size):    print (&amp;#39;x: &amp;#39; + str(pc[i][0]) + &amp;#39;, y : &amp;#39; + str(pc[i][1]) + &amp;#39;, z : &amp;#39; + str(pc[i][2]))        Loaded 19329 data points from test_pcd.pcd with the following fields:x: 5.55542087555, y : 0.753095984459, z : -1.50218582153x: 36.1922683716, y : 4.89982938766, z : 0.637501478195x: 6.65287637711, y : 0.899506211281, z : -1.54991281033x: 23.4230003357, y : 3.16274738312, z : 1.23868751526x: 8.19875049591, y : 1.1070561409, z : -1.60813832283x: 23.224275589, y : 3.13178706169, z : 2.05025148392x: 10.7360458374, y : 1.44585025311, z : -1.71577334404x: 23.258348465, y : 3.12811613083, z : 2.88147902489x: 15.3596839905, y : 2.06306147575, z : -1.90286803246x: 32.7645950317, y : 4.38918924332, z : 6.42568445206Numpy&amp;#47196; &amp;#48320;&amp;#54872;&amp;#182;추후 군집화, 분류, 전처리를 위해서 일반적으로 Numpy로 변환 하여 작업을 수행 In&amp;nbsp;[11]:    pc_array = pc.to_array()print(&amp;quot;pc Type : {}&amp;quot;.format(type(pc)))print(&amp;quot;pc_array Type : {}&amp;quot;.format(type(pc_array)))        pc Type : &amp;lt;type &amp;#39;pcl._pcl.PointCloud&amp;#39;&amp;gt;pc_array Type : &amp;lt;type &amp;#39;numpy.ndarray&amp;#39;&amp;gt;Numpy &amp;#44592;&amp;#48152; &amp;#51221;&amp;#48372; &amp;#52636;&amp;#47141;&amp;#182;In&amp;nbsp;[12]:    print(&amp;quot;pc_array shape : {}&amp;quot;.format(pc_array.shape))print(&amp;quot;pc_array size : {}&amp;quot;.format(pc_array.size))print(&amp;quot;pc_array ndim : {}&amp;quot;.format(pc_array.ndim))print(&amp;quot;pc_array dtype : {}&amp;quot;.format(pc_array.dtype))print(&amp;quot;pc_array nbytes : {} bytes&amp;quot;.format(pc_array.nbytes))        pc_array shape : (19329, 3)pc_array size : 57987pc_array ndim : 2pc_array dtype : float32pc_array nbytes : 231948 bytespcd&amp;#47196; &amp;#51200;&amp;#51109;&amp;#182;point cloud&amp;#47484; pcd&amp;#47196; &amp;#51200;&amp;#51109;&amp;#182;In&amp;nbsp;[13]:    # 방법 1pcl.save(pc, &amp;#39;pc2pcd.pcd&amp;#39;)#pcl.save_XYZRGBA(pc, &amp;#39;pc2pcd.pcd&amp;#39;) #RGB-D센서에서 주로 사용, x,y,z좌표 이외 색상 정보 포함     In&amp;nbsp;[14]:    # 방법 2pc.to_file(&amp;#39;pc2pcd.pcd&amp;#39;)        Out[14]:0numpy&amp;#47484; pcd&amp;#47196; &amp;#51200;&amp;#51109;&amp;#182;In&amp;nbsp;[15]:    pc_new = pcl.PointCloud()pc_new.from_array(pc_array)pc_new.to_file(&amp;#39;pc2pcd.pcd&amp;#39;)        Out[15]:0      ",
    "url": "http://localhost:4000/docs/200-intro-pcl/210-python-pcl/",
    "relUrl": "/docs/200-intro-pcl/210-python-pcl/"
  },
  "2": {
    "id": "2",
    "title": "Open3D",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;220-open3d                      Open3D&amp;#182;본 챕터에서는 Open3D 기본적인 파일 입력, Numpy변환, 저장 방법에 대하여 정리 하였습니다. In&amp;nbsp;[1]:    %load_ext watermark%watermark -d -v -p numpy        2018-11-22CPython 2.7.12IPython 5.8.0numpy 1.15.4In&amp;nbsp;[2]:    import open3dimport numpy as npimport osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)print(&amp;quot;Open3D Version : {}&amp;quot;.format(open3d.__version__))        Open3D Version : 0.4.0.0Point cloud &amp;#49373;&amp;#49457;&amp;#182;&amp;#48176;&amp;#50676;&amp;#47196; &amp;#49373;&amp;#49457;&amp;#182;In&amp;nbsp;[3]:    pc_array = np.array([[1, 2, 3], [3, 4, 5]], dtype=np.float32)print(pc_array)        [[1. 2. 3.] [3. 4. 5.]]In&amp;nbsp;[4]:    pc = open3d.PointCloud()pc.points = open3d.Vector3dVector(pc_array)print(pc)        PointCloud with 2 points.PCD &amp;#54028;&amp;#51068; &amp;#51069;&amp;#44592;&amp;#182;In&amp;nbsp;[5]:    pc = open3d.read_point_cloud(&amp;quot;./sample/lobby.pcd&amp;quot;)print(pc)        PointCloud with 19329 points.txt &amp;#54028;&amp;#51068; &amp;#51069;&amp;#44592;&amp;#182;In&amp;nbsp;[6]:    !cat ./sample/open3d_xyz.txt        0.0000000000 0.0000000000 0.00000000001.0000000000 0.0000000000 0.00000000000.0000000000 1.0000000000 0.00000000000.0000000000 0.0000000000 1.0000000000In&amp;nbsp;[9]:    open3d.read_point_cloud(&amp;quot;./sample/open3d_xyz.txt&amp;quot;, format=&amp;#39;xyz&amp;#39;)        Out[9]:PointCloud with 4 points.&amp;#51221;&amp;#48372; &amp;#54869;&amp;#51064;&amp;#182;In&amp;nbsp;[10]:    print(&amp;quot;포인트 수 : {}&amp;quot;.format(pc.dimension))        포인트 수 : &amp;lt;bound method PointCloud.dimension of PointCloud with 19329 points.&amp;gt;In&amp;nbsp;[11]:    #print (&amp;#39;Loaded &amp;#39; + str(pc.width * pc.height) + &amp;#39; data points from test_pcd.pcd with the following fields: &amp;#39;)for i in range(0, 10):    print (&amp;#39;x: &amp;#39; + str(pc.points[i][0]) + &amp;#39;, y : &amp;#39; + str(pc.points[i][1]) + &amp;#39;, z : &amp;#39; + str(pc.points[i][2]))        x: 5.555420875549316, y : 0.7530959844589233, z : -1.5021858215332031x: 36.19226837158203, y : 4.899829387664795, z : 0.6375014781951904x: 6.652876377105713, y : 0.8995062112808228, z : -1.5499128103256226x: 23.42300033569336, y : 3.162747383117676, z : 1.238687515258789x: 8.198750495910645, y : 1.1070561408996582, z : -1.6081383228302002x: 23.224275588989258, y : 3.131787061691284, z : 2.0502514839172363x: 10.736045837402344, y : 1.4458502531051636, z : -1.715773344039917x: 23.25834846496582, y : 3.1281161308288574, z : 2.881479024887085x: 15.359683990478516, y : 2.063061475753784, z : -1.9028680324554443x: 32.76459503173828, y : 4.38918924331665, z : 6.425684452056885Numpy&amp;#47196; &amp;#48320;&amp;#54872;&amp;#182;추후 군집화, 분류, 전처리를 위해서 일반적으로 Numpy로 변환 하여 작업을 수행 In&amp;nbsp;[12]:    pc_array = np.asarray(pc.points)print(&amp;quot;pc Type : {}&amp;quot;.format(type(pc)))print(&amp;quot;pc_array Type : {}&amp;quot;.format(type(pc_array)))        pc Type : &amp;lt;class &amp;#39;open3d.open3d.PointCloud&amp;#39;&amp;gt;pc_array Type : &amp;lt;type &amp;#39;numpy.ndarray&amp;#39;&amp;gt;Numpy &amp;#44592;&amp;#48152; &amp;#51221;&amp;#48372; &amp;#52636;&amp;#47141;&amp;#182;In&amp;nbsp;[13]:    print(&amp;quot;pc_array shape : {}&amp;quot;.format(pc_array.shape))print(&amp;quot;pc_array size : {}&amp;quot;.format(pc_array.size))print(&amp;quot;pc_array ndim : {}&amp;quot;.format(pc_array.ndim))print(&amp;quot;pc_array dtype : {}&amp;quot;.format(pc_array.dtype))print(&amp;quot;pc_array nbytes : {} bytes&amp;quot;.format(pc_array.nbytes))        pc_array shape : (19329, 3)pc_array size : 57987pc_array ndim : 2pc_array dtype : float64pc_array nbytes : 463896 bytespcd&amp;#47196; &amp;#51200;&amp;#51109;&amp;#182;point cloud&amp;#47484; pcd&amp;#47196; &amp;#51200;&amp;#51109;&amp;#182;In&amp;nbsp;[14]:    open3d.write_point_cloud(&amp;quot;pc2pcd.pcd&amp;quot;, pc)#The supported extension names are: pcd, ply, xyz, xyzrgb, xyzn, pts.        Out[14]:Truenumpy&amp;#47484; pcd&amp;#47196; &amp;#51200;&amp;#51109;&amp;#182;In&amp;nbsp;[15]:    pc_new = open3d.PointCloud()pc_new.points = open3d.Vector3dVector(pc_array)open3d.write_point_cloud(&amp;quot;pc2pcd.pcd&amp;quot;, pc_new)        Out[15]:True      ",
    "url": "http://localhost:4000/docs/200-intro-pcl/220-open3d/",
    "relUrl": "/docs/200-intro-pcl/220-open3d/"
  },
  "3": {
    "id": "3",
    "title": "Down Sampling",
    "content": "Down sampling점군 Resampling은 목적에 따라서 점군의 수를 줄이거나 늘리는것을 의미 합니다.  점군을 줄이는 것을 다운샘플링이라 하며, 연산 부하등의 목적으로 수행 합니다.          Voxel Grid        점군을 늘리는 것을 업샘플링이라 하며, 탐지/식별 정확도 향상 등을 목적으로 수행 합니다.          surface reconstruction      본 챕터에서는 다운샘플링 중 voxelization을 통해서 voxel Grid를 생성 하는 부분만을 다루고 있습니다.",
    "url": "http://localhost:4000/docs/300-downsampling",
    "relUrl": "/docs/300-downsampling"
  },
  "4": {
    "id": "4",
    "title": "Voxelization",
    "content": "Voxelization본 챕터에서는 다운샘플링 기법중 하나인 voxelizattion 방법에 대하여 다루고 있습니다.3D velxel Grid는 Point의 집합로 이루어진 대상을 Voxel의 집합으로 표현하는 것을 의미합니다.  복셀(voxel) : 3차원 공간에서 정규 격자 단위의 값을 나타낸다. 복셀이라는 용어는 부피 (volume)와 픽셀 (pixel)을 조합한 혼성어 [wikipedia]자세한 내용은 Downsampling a PointCloud using a VoxelGrid filter를 참고 하시면 됩니다.%load_ext watermark%watermark -d -v -p pcl,numpyThe watermark extension is already loaded. To reload it, use:  %reload_ext watermark2018-11-23CPython 3.5.2IPython 6.4.0pcl unknownnumpy 1.14.5# -*- coding: utf-8 -*-from __future__ import print_functionimport pclimport numpy as npimport osos.chdir(&quot;/workspace/3D_People_Detection_Tracking&quot;)Voxelization 정의입력  pcl_data : point cloud  leaf_size : Vox 크기출력  voxelized point clouddef do_voxel_grid_downssampling(pcl_data,leaf_size):    '''    Create a VoxelGrid filter object for a input point cloud    :param pcl_data: point cloud data subscriber    :param leaf_size: voxel(or leaf) size    :return: Voxel grid downsampling on point cloud    :https://github.com/fouliex/RoboticPerception    '''    vox = pcl_data.make_voxel_grid_filter()    vox.set_leaf_size(leaf_size, leaf_size, leaf_size) # The bigger the leaf size the less information retained    return  vox.filter()PCD 파일 읽기cloud = pcl.load(&quot;./sample/lobby.pcd&quot;) # Deprecated; use pcl.load instead.print(cloud)&amp;lt;PointCloud of 19329 points&amp;gt;Voxelization 수행LEAF_SIZE = 0.01 #RGB-D센서의 경우 0.01 추천, Lidar의 경우 좀더 큰값 추천cloud = do_voxel_grid_downssampling(cloud,LEAF_SIZE)print(cloud)&amp;lt;PointCloud of 19329 points&amp;gt;LEAF_SIZE = 0.1 #RGB-D센서의 경우 0.01 추천, Lidar의 경우 좀더 큰값 추천cloud = do_voxel_grid_downssampling(cloud,LEAF_SIZE)print(cloud)&amp;lt;PointCloud of 9413 points&amp;gt;LEAF_SIZE = 1.0 #RGB-D센서의 경우 0.01 추천, Lidar의 경우 좀더 큰값 추천cloud = do_voxel_grid_downssampling(cloud,LEAF_SIZE)print(cloud)&amp;lt;PointCloud of 1171 points&amp;gt;",
    "url": "http://localhost:4000/docs/300-downsampling/310-voxelization/",
    "relUrl": "/docs/300-downsampling/310-voxelization/"
  },
  "5": {
    "id": "5",
    "title": "Voxelization-Jupyter",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;320-voxelization                      Voxelization&amp;#182;본 챕터에서는 다운샘플링 기법중 하나인 voxelizattion 방법에 대하여 다루고 있습니다.3D velxel Grid는 Point의 집합로 이루어진 대상을 Voxel의 집합으로 표현하는 것을 의미합니다.복셀(voxel) : 3차원 공간에서 정규 격자 단위의 값을 나타낸다. 복셀이라는 용어는 부피 (volume)와 픽셀 (pixel)을 조합한 혼성어 [wikipedia]자세한 내용은 Downsampling a PointCloud using a VoxelGrid filter를 참고 하시면 됩니다.In&amp;nbsp;[20]:    %load_ext watermark%watermark -d -v -p pcl,numpy        The watermark extension is already loaded. To reload it, use:  %reload_ext watermark2018-11-23CPython 3.5.2IPython 6.4.0pcl unknownnumpy 1.14.5In&amp;nbsp;[28]:    # -*- coding: utf-8 -*-from __future__ import print_functionimport pclimport numpy as npimport osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)    Voxelization &amp;#51221;&amp;#51032;&amp;#182;입력pcl_data : point cloudleaf_size : Vox 크기출력voxelized point cloudIn&amp;nbsp;[30]:    def do_voxel_grid_downssampling(pcl_data,leaf_size):    &amp;#39;&amp;#39;&amp;#39;    Create a VoxelGrid filter object for a input point cloud    :param pcl_data: point cloud data subscriber    :param leaf_size: voxel(or leaf) size    :return: Voxel grid downsampling on point cloud    :https://github.com/fouliex/RoboticPerception    &amp;#39;&amp;#39;&amp;#39;    vox = pcl_data.make_voxel_grid_filter()    vox.set_leaf_size(leaf_size, leaf_size, leaf_size) # The bigger the leaf size the less information retained    return  vox.filter()    PCD &amp;#54028;&amp;#51068; &amp;#51069;&amp;#44592;&amp;#182;In&amp;nbsp;[31]:    cloud = pcl.load(&amp;quot;./sample/lobby.pcd&amp;quot;) # Deprecated; use pcl.load instead.print(cloud)        &amp;lt;PointCloud of 19329 points&amp;gt;Voxelization &amp;#49688;&amp;#54665;&amp;#182;In&amp;nbsp;[24]:    LEAF_SIZE = 0.01 #RGB-D센서의 경우 0.01 추천, Lidar의 경우 좀더 큰값 추천 cloud = do_voxel_grid_downssampling(cloud,LEAF_SIZE)print(cloud)        &amp;lt;PointCloud of 19329 points&amp;gt;In&amp;nbsp;[25]:    LEAF_SIZE = 0.1 #RGB-D센서의 경우 0.01 추천, Lidar의 경우 좀더 큰값 추천 cloud = do_voxel_grid_downssampling(cloud,LEAF_SIZE)print(cloud)        &amp;lt;PointCloud of 9413 points&amp;gt;In&amp;nbsp;[26]:    LEAF_SIZE = 1.0 #RGB-D센서의 경우 0.01 추천, Lidar의 경우 좀더 큰값 추천 cloud = do_voxel_grid_downssampling(cloud,LEAF_SIZE)print(cloud)        &amp;lt;PointCloud of 1171 points&amp;gt;In&amp;nbsp;[&amp;nbsp;]:              ",
    "url": "http://localhost:4000/docs/300-downsampling/320-voxelization/",
    "relUrl": "/docs/300-downsampling/320-voxelization/"
  },
  "6": {
    "id": "6",
    "title": "Voxelization-ROS",
    "content": "",
    "url": "http://localhost:4000/docs/300-downsampling/330-Voxeliaztion-ros/",
    "relUrl": "/docs/300-downsampling/330-Voxeliaztion-ros/"
  },
  "7": {
    "id": "7",
    "title": "PassThrough Filter",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;410-PassThrough_filter                      PassThrough Filter&amp;#182;본 챕터에서는 RoI 추출 방법 중 하나인 PassThrough Filter에 대하여 다루고 있습니다.PassThrough Filter는 입력값으로 관심 영역의 x,y,z의 최대/최소값을 받아 crop하는 방식으로, 직관적이지만 정교한 부분을 제거하지는 못하는 단점이 있습니다.자세한 내용은 Filtering a PointCloud using a PassThrough filter를 참고 하시면 됩니다.In&amp;nbsp;[1]:    %load_ext watermark%watermark -d -v -p pcl,numpy        2018-11-23CPython 3.5.2IPython 6.4.0pcl unknownnumpy 1.14.5In&amp;nbsp;[2]:    # -*- coding: utf-8 -*-from __future__ import print_functionimport pclimport numpy as npimport osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)    In&amp;nbsp;[9]:    from include.visualization_helper import *%matplotlib inline    PassThough Filter &amp;#51221;&amp;#51032;&amp;#182;입력pcl_data : point cloudfilter_axis : 제거할 축 (x or y or z)axis_min : 최소 크기axis_max : 최대 크기출력point cloudIn&amp;nbsp;[10]:    def do_passthrough(pcl_data,filter_axis,axis_min,axis_max):    &amp;#39;&amp;#39;&amp;#39;    Create a PassThrough  object and assigns a filter axis and range.    :param pcl_data: point could data subscriber    :param filter_axis: filter axis    :param axis_min: Minimum  axis to the passthrough filter object    :param axis_max: Maximum axis to the passthrough filter object    :return: passthrough on point cloud    :https://github.com/fouliex/RoboticPerception    &amp;#39;&amp;#39;&amp;#39;    passthrough = pcl_data.make_passthrough_filter()    passthrough.set_filter_field_name(filter_axis)    passthrough.set_filter_limits(axis_min, axis_max)    return passthrough.filter()    PCD &amp;#54028;&amp;#51068; &amp;#51069;&amp;#44592;&amp;#182;In&amp;nbsp;[17]:    cloud = pcl.load(&amp;quot;./sample/lobby.pcd&amp;quot;) # Deprecated; use pcl.load instead.print(cloud)        &amp;lt;PointCloud of 19329 points&amp;gt;In&amp;nbsp;[18]:    visualization2D_xyz(cloud.to_array())        (x) : 92.2m(y) : 87.5m(z) : 10.3m    PassThough Filter &amp;#49688;&amp;#54665;&amp;#182;In&amp;nbsp;[19]:    filter_axis = &amp;#39;x&amp;#39;axis_min = 1.0axis_max = 20.0cloud = do_passthrough(cloud, filter_axis, axis_min, axis_max)    In&amp;nbsp;[20]:    visualization2D_xyz(cloud.to_array())        (x) : 19.0m(y) : 87.5m(z) : 8.7m    In&amp;nbsp;[22]:    filter_axis = &amp;#39;y&amp;#39;axis_min = -7.0axis_max = 5.5cloud = do_passthrough(cloud, filter_axis, axis_min, axis_max)    In&amp;nbsp;[23]:    visualization2D_xyz(cloud.to_array())        (x) : 19.0m(y) : 12.5m(z) : 2.3m    In&amp;nbsp;[25]:    visualization3D_xyz(cloud.to_array())        (x) : 19.0m(y) : 12.5m(z) : 2.3m    In&amp;nbsp;[27]:    filter_axis = &amp;#39;z&amp;#39;axis_min = -1.2axis_max = 10.0cloud = do_passthrough(cloud, filter_axis, axis_min, axis_max)    In&amp;nbsp;[28]:    visualization3D_xyz(cloud.to_array())        (x) : 2.7m(y) : 9.8m(z) : 1.5m    PassThrough필터의 z축 필터링을 통해서 바닥제거도 가능합니다.단, Lidar가 기울어져있으면 근거리와 원거리의 z값이 다르기 때문에 설치시 조심해야 합니다.      ",
    "url": "http://localhost:4000/docs/400-roi-filter/410-PassThrough_filter/",
    "relUrl": "/docs/400-roi-filter/410-PassThrough_filter/"
  },
  "8": {
    "id": "8",
    "title": "Conditional Filter",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;420-conditional_filter                      Conditional Filter&amp;#182;본 챕터에서는 RoI 추출 방법 중 하나인 Conditional Filter에 대하여 다루고 있습니다.x,y,z값을 GT, GE, LT, LE, EQ.조건에 맞추어 제거 할수 있습니다.자세한 내용은 Removing outliers using a Conditional or RadiusOutlier removal를 참고 하시면 됩니다.PCL에서는 Conditional Filter를 Noise제거용으로 소개 하고 있지만, RoI추출에 좀더 유용한것 같아 RoI 추출 기법으로 분류 하였습니다.In&amp;nbsp;[21]:    %load_ext watermark%watermark -d -v -p pcl,numpy        2018-11-23CPython 3.5.2IPython 6.4.0pcl unknownnumpy 1.14.5In&amp;nbsp;[50]:    # -*- coding: utf-8 -*-from __future__ import print_functionimport pclimport numpy as npnp.warnings.filterwarnings(&amp;#39;ignore&amp;#39;) #경고 메시지 출력 안함 import osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)    In&amp;nbsp;[51]:    from include.visualization_helper import *%matplotlib inline    do_conditional_outlier_filtering &amp;#51221;&amp;#51032;&amp;#182;입력pcl_data : point cloudfilter_axis : 제거할 축 (x or y or z)axis_min : 최소 크기axis_max : 최대 크기출력point cloudIn&amp;nbsp;[52]:    def do_conditional_outlier_filtering(pcl_data, axis,gt, lt):    &amp;#39;&amp;#39;&amp;#39;    :param pcl_data: point could data subscriber    :axis :     :gt :    :lt :    :return: point cloud data    eg) do_conditional_outlier_filtering(cloud, &amp;#39;x&amp;#39;,1.0,20.0)    : https://github.com/hunjung-lim/3D_People_Detection_Tracking    &amp;#39;&amp;#39;&amp;#39;    #axis_str = axis.str()    range_cond = pcl_data.make_ConditionAnd()    range_cond.add_Comparison2(axis, pcl.CythonCompareOp_Type.GT, gt)    range_cond.add_Comparison2(axis, pcl.CythonCompareOp_Type.LT, lt)    # build the filter    condrem = pcl_data.make_ConditionalRemoval(range_cond)    condrem.set_KeepOrganized(True)    return condrem.filter ()    PCD &amp;#54028;&amp;#51068; &amp;#51069;&amp;#44592;&amp;#182;In&amp;nbsp;[55]:    cloud = pcl.load(&amp;quot;./sample/lobby.pcd&amp;quot;) # Deprecated; use pcl.load instead.    In&amp;nbsp;[56]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))if (cloud.size!=0):    visualization2D_xyz(cloud.to_array())        Number of Points : 19329(x) : 92.2m(y) : 87.5m(z) : 10.3m    do_conditional_outlier_filtering &amp;#49688;&amp;#54665;&amp;#182;In&amp;nbsp;[57]:    axis = &amp;#39;x&amp;#39;gt = 1.0lt = 20.0cloud = do_conditional_outlier_filtering(cloud, axis,gt, lt)    In&amp;nbsp;[58]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))if (cloud.size!=0):    visualization2D_xyz(cloud.to_array())        Number of Points : 19329(x) : nanm(y) : nanm(z) : nanm    In&amp;nbsp;[59]:    axis = &amp;#39;y&amp;#39;gt = -7.0lt = 5.5cloud = do_conditional_outlier_filtering(cloud, axis,gt, lt)    In&amp;nbsp;[60]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))if (cloud.size!=0):    visualization2D_xyz(cloud.to_array())        Number of Points : 19329(x) : nanm(y) : nanm(z) : nanm    In&amp;nbsp;[62]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))if (cloud.size!=0):    visualization3D_xyz(cloud.to_array())        Number of Points : 19329(x) : nanm(y) : nanm(z) : nanm    In&amp;nbsp;[63]:    axis = &amp;#39;z&amp;#39;gt = -1.2lt = 10.0cloud = do_conditional_outlier_filtering(cloud, axis,gt, lt)    In&amp;nbsp;[65]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))if (cloud.size!=0):    visualization3D_xyz(cloud.to_array())        Number of Points : 19329(x) : nanm(y) : nanm(z) : nanm    Conditional 필터의 z축 필터링을 통해서 바닥제거도 가능합니다.단, Lidar가 기울어져있으면 근거리와 원거리의 z값이 다르기 때문에 설치시 조심해야 합니다.      ",
    "url": "http://localhost:4000/docs/400-roi-filter/420-conditional_filter/",
    "relUrl": "/docs/400-roi-filter/420-conditional_filter/"
  },
  "9": {
    "id": "9",
    "title": "Noise Filtering",
    "content": "Noise FilteringLidar는 센서 특성상 물체가 존재 하지 않아도 먼지등으로 인해 point가 생성 됩니다. 이렇게 생성된 point들을 Noise로 간주 하고 제거 하는 작업을 진행 해야 합니다.다행히 이러한 노이즈들은 정상적인 ponint 대비 빈 공간에 소수의 점들만 탐지 되므로 이러한 특성을 이용하여 제거 할수 있습니다.      Statistical based        Radius based    [중요] 현재 Radius based 방식은 정상 동작 하지 않는다고 합니다. 파라미터를 바꾸어도 결과가 ‘0’이라고 하네요. [참고] - 2018.06.11",
    "url": "http://localhost:4000/docs/500-noise-filter",
    "relUrl": "/docs/500-noise-filter"
  },
  "10": {
    "id": "10",
    "title": "Statistical Filter",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;510-Statistical_filter                      Statistical Outlier Removal filter&amp;#182;본 챕터에서는 Noise 제거 방법 중 하나인 Statistical Outlier Removal filter에 대하여 다루고 있습니다.자세한 내용은 Removing outliers using a Statistical OutlierRemoval filter를 참고 하시면 됩니다.In&amp;nbsp;[36]:    %load_ext watermark%watermark -d -v -p pcl,numpy        The watermark extension is already loaded. To reload it, use:  %reload_ext watermark2018-11-23CPython 3.5.2IPython 6.4.0pcl unknownnumpy 1.14.5In&amp;nbsp;[11]:    # -*- coding: utf-8 -*-from __future__ import print_functionimport pclimport numpy as npimport randomimport osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)    In&amp;nbsp;[17]:    from include.visualization_helper import *%matplotlib inline    do_statistical_outlier_filtering &amp;#51221;&amp;#51032;&amp;#182;입력pcl_data : point cloudmean_k : 분석시 참고할 주변 점의 수tresh : Noise로 판단시 사용할 거리 정보출력point cloudIn&amp;nbsp;[12]:    def do_statistical_outlier_filtering(pcl_data,mean_k,tresh):    &amp;#39;&amp;#39;&amp;#39;    :param pcl_data: point could data subscriber    :param mean_k:  number of neighboring points to analyze for any given point    :param tresh:   Any point with a mean distance larger than global will be considered outlier    :return: Statistical outlier filtered point cloud data    eg) cloud = do_statistical_outlier_filtering(cloud,10,0.001)    : https://github.com/fouliex/RoboticPerception    &amp;#39;&amp;#39;&amp;#39;    outlier_filter = pcl_data.make_statistical_outlier_filter()    outlier_filter.set_mean_k(mean_k)    outlier_filter.set_std_dev_mul_thresh(tresh)    return outlier_filter.filter()    &amp;#47004;&amp;#45924; Point Cloud &amp;#49373;&amp;#49457;&amp;#182;In&amp;nbsp;[29]:    cloud = pcl.PointCloud()points = np.zeros((5, 3), dtype=np.float32)RAND_MAX = 1024.0for i in range(0, 5):    points[i][0] = 1024 * random.random () / RAND_MAX    points[i][1] = 1024 * random.random () / RAND_MAX    points[i][2] = 1024 * random.random () / RAND_MAXcloud.from_array(points)    In&amp;nbsp;[27]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))for i in range(0, cloud.size):    print (&amp;#39;x: &amp;#39;  + str(cloud[i][0]) + &amp;#39;, y : &amp;#39; + str(cloud[i][1])  + &amp;#39;, z : &amp;#39; + str(cloud[i][2]))if (cloud.size!=0):    visualization2D_xyz(cloud.to_array())        Number of Points : 5x: 0.47851642966270447, y : 0.03497461602091789, z : 0.535773754119873x: 0.3981524109840393, y : 0.1518072634935379, z : 0.09672793000936508x: 0.7707034349441528, y : 0.07869423180818558, z : 0.6807618141174316x: 0.13448742032051086, y : 0.6192044019699097, z : 0.35335949063301086x: 0.5647233724594116, y : 0.20890095829963684, z : 0.6382982134819031(x) : 0.6m(y) : 0.6m(z) : 0.6m    do_statistical_outlier_filtering &amp;#49688;&amp;#54665;&amp;#182;In&amp;nbsp;[14]:    mean_k = 10tresh = 0.001    In&amp;nbsp;[30]:    cloud = do_statistical_outlier_filtering(cloud,mean_k,tresh)    In&amp;nbsp;[31]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))for i in range(0, cloud.size):    print (&amp;#39;x: &amp;#39;  + str(cloud[i][0]) + &amp;#39;, y : &amp;#39; + str(cloud[i][1])  + &amp;#39;, z : &amp;#39; + str(cloud[i][2]))if (cloud.size!=0):    visualization2D_xyz(cloud.to_array())        Number of Points : 2x: 0.8091028332710266, y : 0.8478883504867554, z : 0.9810506701469421x: 0.7552645802497864, y : 0.975726842880249, z : 0.8663910627365112(x) : 0.1m(y) : 0.1m(z) : 0.1m          ",
    "url": "http://localhost:4000/docs/500-noise-filter/510-Statistical_filter/",
    "relUrl": "/docs/500-noise-filter/510-Statistical_filter/"
  },
  "11": {
    "id": "11",
    "title": "Radius Filter",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;520-radius_filter                      Radius Outlier Removal filter&amp;#182;본 챕터에서는 Noise 제거 방법 중 하나인 Radius Outlier Removal filter에 대하여 다루고 있습니다.지정된 반경안에 지정된 수 만큼의 포인트가 없을 경우 outlier로 판단 합니다. (You must specify a search radius and the minimum number of neighbors than a point must have to avoid being labelled as outlier)자세한 내용은 Removing outliers using a Conditional or RadiusOutlier removal를 참고 하시면 됩니다.[중요] 현재 정상 동작 하지 않는다고 합니다. 파라미터를 바꾸어도 결과가 '0'이라고 하네요. [참고] - 2018.06.11In&amp;nbsp;[54]:    %load_ext watermark%watermark -d -v -p pcl,numpy        2018-11-23CPython 3.5.2IPython 6.4.0pcl unknownnumpy 1.14.5In&amp;nbsp;[55]:    # -*- coding: utf-8 -*-from __future__ import print_functionimport pclimport numpy as npimport randomimport osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)    In&amp;nbsp;[56]:    from include.visualization_helper import *%matplotlib inline    Radius_outlier_filtering &amp;#51221;&amp;#51032;&amp;#182;입력pcl_data : point cloudradius_search : 검색 반경Min_Neighbors : Noise로 간주되지 않을 최소 poin 수 출력point cloudIn&amp;nbsp;[57]:    def do_radius_outlier_filtering(pcl_data, radius_search,Min_Neighbors):    &amp;#39;&amp;#39;&amp;#39;    :param pcl_data: point could data subscriber    :radius_search:      :Min_Neighbors : a number of neighbors which every index must have                      within a specified radius to remain in the PointCloud      :return: point cloud data    eg) cloud = do_radius_outlier_filtering(cloud,0.8, 2)    :https://github.com/hunjung-lim/3D_People_Detection_Tracking    &amp;#39;&amp;#39;&amp;#39;    outrem = pcl_data.make_RadiusOutlierRemoval()    outrem.set_radius_search(radius_search)    outrem.set_MinNeighborsInRadius(Min_Neighbors)    return outrem.filter ()    &amp;#47004;&amp;#45924; Point Cloud &amp;#49373;&amp;#49457;&amp;#182;In&amp;nbsp;[58]:    cloud = pcl.PointCloud()points = np.zeros((5, 3), dtype=np.float32)RAND_MAX = 1024.0for i in range(0, 5):    points[i][0] = 1024 * random.random () / RAND_MAX    points[i][1] = 1024 * random.random () / RAND_MAX    points[i][2] = 1024 * random.random () / RAND_MAXcloud.from_array(points)    In&amp;nbsp;[59]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))for i in range(0, cloud.size):    print (&amp;#39;x: &amp;#39;  + str(cloud[i][0]) + &amp;#39;, y : &amp;#39; + str(cloud[i][1])  + &amp;#39;, z : &amp;#39; + str(cloud[i][2]))if (cloud.size!=0):    visualization2D_xyz(cloud.to_array())        Number of Points : 5x: 0.3189416527748108, y : 0.6415157318115234, z : 0.6303199529647827x: 0.6143890619277954, y : 0.9941856265068054, z : 0.8331842422485352x: 0.5174641609191895, y : 0.4453221261501312, z : 0.858452320098877x: 0.86646968126297, y : 0.34745171666145325, z : 0.44225549697875977x: 0.27557268738746643, y : 0.9309353232383728, z : 0.03610602021217346(x) : 0.6m(y) : 0.6m(z) : 0.8m    Radius_outlier_filtering&amp;#49688;&amp;#54665;&amp;#182;In&amp;nbsp;[60]:    radius_search = 0.08Min_Neighbors = 2    In&amp;nbsp;[61]:    cloud = do_radius_outlier_filtering(cloud, radius_search, Min_Neighbors)    In&amp;nbsp;[62]:    print(&amp;quot;Number of Points : {}&amp;quot;.format(cloud.size))for i in range(0, cloud.size):    print (&amp;#39;x: &amp;#39;  + str(cloud[i][0]) + &amp;#39;, y : &amp;#39; + str(cloud[i][1])  + &amp;#39;, z : &amp;#39; + str(cloud[i][2]))if (cloud.size!=0):    visualization2D_xyz(cloud.to_array())        Number of Points : 0      ",
    "url": "http://localhost:4000/docs/500-noise-filter/520-radius_filter/",
    "relUrl": "/docs/500-noise-filter/520-radius_filter/"
  },
  "12": {
    "id": "12",
    "title": "Plane Removal",
    "content": "  배경 제거 기술",
    "url": "http://localhost:4000/docs/600-plane-removal",
    "relUrl": "/docs/600-plane-removal"
  },
  "13": {
    "id": "13",
    "title": "RANSAC based Plane Removal",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;610-ransac-removal                      PassThrough Filter&amp;#182;본 챕터에서는 RoI 추출 방법 중 하나인 PassThrough Filter에 대하여 다루고 있습니다.PassThrough Filter는 입력값으로 관심 영역의 x,y,z의 최대/최소값을 받아 crop하는 방식으로, 직관적이지만 정교한 부분을 제거하지는 못하는 단점이 있습니다.자세한 내용은 Filtering a PointCloud using a PassThrough filter를 참고 하시면 됩니다.In&amp;nbsp;[1]:    %load_ext watermark%watermark -d -v -p pcl,numpy        2018-11-23CPython 3.5.2IPython 6.4.0pcl unknownnumpy 1.14.5In&amp;nbsp;[2]:    # -*- coding: utf-8 -*-from __future__ import print_functionimport pclimport numpy as npimport osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)    In&amp;nbsp;[9]:    from include.visualization_helper import *%matplotlib inline    PassThough Filter &amp;#51221;&amp;#51032;&amp;#182;입력pcl_data : point cloudfilter_axis : 제거할 축 (x or y or z)axis_min : 최소 크기axis_max : 최대 크기출력point cloudIn&amp;nbsp;[10]:    def do_passthrough(pcl_data,filter_axis,axis_min,axis_max):    &amp;#39;&amp;#39;&amp;#39;    Create a PassThrough  object and assigns a filter axis and range.    :param pcl_data: point could data subscriber    :param filter_axis: filter axis    :param axis_min: Minimum  axis to the passthrough filter object    :param axis_max: Maximum axis to the passthrough filter object    :return: passthrough on point cloud    :https://github.com/fouliex/RoboticPerception    &amp;#39;&amp;#39;&amp;#39;    passthrough = pcl_data.make_passthrough_filter()    passthrough.set_filter_field_name(filter_axis)    passthrough.set_filter_limits(axis_min, axis_max)    return passthrough.filter()    PCD &amp;#54028;&amp;#51068; &amp;#51069;&amp;#44592;&amp;#182;In&amp;nbsp;[17]:    cloud = pcl.load(&amp;quot;./sample/lobby.pcd&amp;quot;) # Deprecated; use pcl.load instead.print(cloud)        &amp;lt;PointCloud of 19329 points&amp;gt;In&amp;nbsp;[18]:    visualization2D_xyz(cloud.to_array())        (x) : 92.2m(y) : 87.5m(z) : 10.3m    PassThough Filter &amp;#49688;&amp;#54665;&amp;#182;In&amp;nbsp;[19]:    filter_axis = &amp;#39;x&amp;#39;axis_min = 1.0axis_max = 20.0cloud = do_passthrough(cloud, filter_axis, axis_min, axis_max)    In&amp;nbsp;[20]:    visualization2D_xyz(cloud.to_array())        (x) : 19.0m(y) : 87.5m(z) : 8.7m    In&amp;nbsp;[22]:    filter_axis = &amp;#39;y&amp;#39;axis_min = -7.0axis_max = 5.5cloud = do_passthrough(cloud, filter_axis, axis_min, axis_max)    In&amp;nbsp;[23]:    visualization2D_xyz(cloud.to_array())        (x) : 19.0m(y) : 12.5m(z) : 2.3m    In&amp;nbsp;[25]:    visualization3D_xyz(cloud.to_array())        (x) : 19.0m(y) : 12.5m(z) : 2.3m    In&amp;nbsp;[27]:    filter_axis = &amp;#39;z&amp;#39;axis_min = -1.2axis_max = 10.0cloud = do_passthrough(cloud, filter_axis, axis_min, axis_max)    In&amp;nbsp;[28]:    visualization3D_xyz(cloud.to_array())        (x) : 2.7m(y) : 9.8m(z) : 1.5m    PassThrough필터의 z축 필터링을 통해서 바닥제거도 가능합니다.단, Lidar가 기울어져있으면 근거리와 원거리의 z값이 다르기 때문에 설치시 조심해야 합니다.      ",
    "url": "http://localhost:4000/docs/600-plane-removal/610-ransac-removal/",
    "relUrl": "/docs/600-plane-removal/610-ransac-removal/"
  },
  "14": {
    "id": "14",
    "title": "System Setup",
    "content": "환경 구성실습을 위해 구성한 환경은 아래와 같습니다.  Host PC : Ubuntu 18.04 with ROS (Optional)  Guest PC(Docker) : Ubuntu 16.04 with Python-PCLHost PC일반적인 방법은 Docker 없이 Host PC에 ubuntu, ROS, python-pcl을 모두 설치 하여 사용하는 것이지만, 개발환경 분리를 위하여 Docker를 이용하였습니다.Docker기반으로 구성할 경우 대부분의 작업은 Guest PC에서 이루어 지기 때문에 특별한 요구사항은 없습니다. (따라서, windows에서도 재현 가능합니다.)하지만, 처리 결과를 실시간 확인하기 위해서 ROS의 rviz라는 시각화 툴을 사용하기 위해 선택적으로 ROS설치를 권장 합니다. (Docker에서도 rviz를 실행 할수 있지만 지연이 좀 발생합니다.)Guest PC(Docker)Ubuntu 16, ROS, PCL-python, Open3D, Jupyter가 설치된 Docker를 [여기]에 올려 두었습니다.자세한 실행 방법은 환경구성-Docker활용를 참고 바랍니다.  윈도우를 사용하시는 분은 VMWARE를 사용하거나, 윈도우용 Docker를 이용해도 됩니다.",
    "url": "http://localhost:4000/docs/900-system-setup",
    "relUrl": "/docs/900-system-setup"
  },
  "15": {
    "id": "15",
    "title": "Ubuntu Setup",
    "content": "Ubuntu 환경 구성하기  Docker를 사용하면 되기에 추후 작성 예정입니다.설치 순서는 아래와 같습니다.ROS 설치PCL 설치Jupyter 설치",
    "url": "http://localhost:4000/docs/900-system-setup/910_ubuntu/",
    "relUrl": "/docs/900-system-setup/910_ubuntu/"
  },
  "16": {
    "id": "16",
    "title": "Docker Setup",
    "content": "Docker 환경 구성하기설치 및 실행도커 이미지 받기 : $ docker push adioshun/pcl_to_all:20181122도커 실행 : $ docker run -it --net=host --volume /workspace:/workspace --name 'pcl_to_all' adioshun/pcl_to_all:20181122 /bin/bash  --net=host : Host PC에서 ROS메시지를 받아 시각화 작업시 필요  --volume : jupyter의 기본 작업 폴더로 Host PC와의 폴더 동기화를 위해 필요컨테이너 실행 : $ docker start pcl_to_all실행 확인(Option) : $ docker ps -a도커 접속 : $ docker exec -it pcl_to_all bashDocker 내 실행쥬피터 실행 : jupyter notebook --allow-root웹프라우져 접속 : http://localhost:8888 (접속 암호 : ubuntu)",
    "url": "http://localhost:4000/docs/900-system-setup/920_docker/",
    "relUrl": "/docs/900-system-setup/920_docker/"
  },
  "17": {
    "id": "17",
    "title": "ROS Setup",
    "content": "ROS파일에서 PCD파일 추출 하기http://wiki.ros.org/pcl_rosrosrun pcl_ros bag_to_pcd  / rosrun pcl_ros bag_to_pcd lobby_velodyne.bag /velodyne_points ./lobby_pcd",
    "url": "http://localhost:4000/docs/900-system-setup/930_ros/",
    "relUrl": "/docs/900-system-setup/930_ros/"
  },
  "18": {
    "id": "18",
    "title": "Visualization Tool Setup",
    "content": "시각화 툴",
    "url": "http://localhost:4000/docs/900-system-setup/950_vis/",
    "relUrl": "/docs/900-system-setup/950_vis/"
  },
  "19": {
    "id": "19",
    "title": "Visualization Tool - Jupyter",
    "content": "&amp;lt;!DOCTYPE html&amp;gt;950_viz_jupyter                      Jupyter&amp;#50640;&amp;#49436; Point cloud&amp;#47484; &amp;#49884;&amp;#44033;&amp;#54868;&amp;#182;Matplotlib 기반 시각화k3d 기반 시각화코드는 [여기에]에 올려 두었습니다.In&amp;nbsp;[7]:    # -*- coding: utf-8 -*-from __future__ import print_functionimport osos.chdir(&amp;quot;/workspace/3D_People_Detection_Tracking&amp;quot;)from include.visualization_helper import *%matplotlib inline    In&amp;nbsp;[8]:    import pclpc = pcl.load(&amp;quot;/workspace/_pcd/test_pypcd_xyzrgb.pcd&amp;quot;)pc_arr = pc.to_array()    Matplotlib &amp;#44592;&amp;#48152; &amp;#49884;&amp;#44033;&amp;#54868;&amp;#182;In&amp;nbsp;[9]:    visualization2D_xyz(pc_arr)        (x) : 18.9m(y) : 12.5m(z) : 1.8m    In&amp;nbsp;[10]:    visualization3D_xyz(pc_arr)        (x) : 18.9m(y) : 12.5m(z) : 1.8m    k3d &amp;#44592;&amp;#48152; &amp;#49884;&amp;#44033;&amp;#54868;&amp;#182;설치 및 Jupyter 설정이 필요 합니다. [참고]배포하는 Docker에는 설정이 되어 있으니 바로 실행 하면 됩니다.In&amp;nbsp;[6]:    visualization_inter3D_xyz(pc_arr) # import k3d        2750        (x) : 18.9m(y) : 12.5m(z) : 1.8mIn&amp;nbsp;[&amp;nbsp;]:              ",
    "url": "http://localhost:4000/docs/900-system-setup/950_viz_jupyter/",
    "relUrl": "/docs/900-system-setup/950_viz_jupyter/"
  },
  "20": {
    "id": "20",
    "title": "Home",
    "content": "PCL 정리 노트그동안 살펴 보았던 PCL 사용 및 활용에 대하여 정리 하고자 합니다.PCL은 Point cloud Library의 약어로 Lidar나 RGB-D센서 등으로 수집되는 점군(Point cloud)를 처리 하기 위한 라이브러리 입니다.Point cloud를 처리를 위한 라이브러리로는 PCL, PCL-python, Open3D, pyPCD, Laspy, PCLpy 등이 있습니다.여기서는 PCL-Python과 일부 Open3D를 활용합니다.Environment  언어: python2  라이브러리 : PCL-Python (PCL의 python버젼인)  OS : Ubuntu 16.4 with ROS  센서 : Velodyne Puck (16ch Lidar)  PCL-To-All Docker : Ubuntu 16, ROS, PCL-python, Open3D, Jupyter, etc. 설치Mini Project진행은 Lidar로 수집되는 점군 데이터에서 사람을 추출 하는 3D People Detection 구현을 목표로 하고 있습니다.Release Note2018.11.22 :                   초급      중급      고급                  2018.11.22      0.1 Home/PCL                            2018.11.22      0.2 환경구축                            2018.11.23      1.1 Down Sampling                            2018.11.23      1.2 ROI Filtering                            2018.11.29      1.3 Noise Filtering                            2018.11.29      1.4 Plane Removal                            2018.11.30      1.5 Clustering                            2018.12.03             2.1 Background Removal                     2018.12.04             2.2 Clustering                     2018.12.05             2.3 Tracking                     2019.03.01                    3.1 Clustering              2019.04.01                    3.2 Classification              2019.05.01                    3.3 Tracking      ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },
  "21": {
    "id": "21",
    "title": "123",
    "content": "surround_view&amp;lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML&quot;&amp;gt;&amp;lt;/script&amp;gt;&amp;lt;!-- MathJax configuration --&amp;gt;&amp;lt;script type=&quot;text/x-mathjax-config&quot;&amp;gt;MathJax.Hub.Config({    tex2jax: {        inlineMath: [ ['$','$'], [&quot;  (&quot;,&quot;  )&quot;] ],        displayMath: [ ['$$','$$'], [&quot;  [&quot;,&quot;  ]&quot;] ],        processEscapes: true,        processEnvironments: true    },    // Center justify equations in code and markdown cells. Elsewhere    // we use CSS to left justify single line equations in code cells.    displayAlign: 'center',    &quot;HTML-CSS&quot;: {        styles: {'.MathJax_Display': {&quot;margin&quot;: 0}},        linebreaks: { automatic: true }    }});&amp;lt;/script&amp;gt;&amp;lt;!-- End of mathjax configuration --&amp;gt;    In&amp;nbsp;[2]:    SEED = 202# std libsimport glob# num libsimport mathimport randomimport numpy as nprandom.seed(SEED)np.random.seed(SEED)import cv2    In&amp;nbsp;[3]:    ##   cylindrial projectionSURROUND_U_STEP = 1.    #resolutionSURROUND_V_STEP = 1.33SURROUND_U_MIN, SURROUND_U_MAX = np.array([0,    360])/SURROUND_U_STEP  # horizontal of cylindrial projectionSURROUND_V_MIN, SURROUND_V_MAX = np.array([-90,   90])/SURROUND_V_STEP  # vertical   of cylindrial projection    In&amp;nbsp;[22]:    def lidar_to_surround_coords_360(x, y, z, d ):    u =   np.arctan2(x, y)/np.pi*360 /SURROUND_U_STEP    v = - np.arctan2(z, d)/np.pi*360 /SURROUND_V_STEP    u = (u +90)%360  ##&amp;lt;todo&amp;gt; car will be spit into 2 at boundary  ...    u = np.rint(u)    v = np.rint(v)    u = (u - SURROUND_U_MIN).astype(np.uint8)    v = (v - SURROUND_V_MIN).astype(np.uint8)    return u,v    In&amp;nbsp;[4]:    def lidar_to_surround_coords_180(x, y, z, d ):    u =   np.arctan2(x, y)/np.pi*180 /SURROUND_U_STEP    v = - np.arctan2(z, d)/np.pi*180 /SURROUND_V_STEP    u = (u +90)%360  ##&amp;lt;todo&amp;gt; car will be spit into 2 at boundary  ...    u = np.rint(u)    v = np.rint(v)    u = (u - SURROUND_U_MIN).astype(np.uint8)    v = (v - SURROUND_V_MIN).astype(np.uint8)    return u,v    In&amp;nbsp;[23]:    def lidar_to_surround(lidar):    def normalise_to_255(a):        return (((a - min(a)) / float(max(a) - min(a))) * 255).astype(np.uint8)    x = lidar[&amp;#39;x&amp;#39;]    y = lidar[&amp;#39;y&amp;#39;]    z = lidar[&amp;#39;z&amp;#39;]    r = lidar[&amp;#39;intensity&amp;#39;]    d = np.sqrt(x ** 2 + y ** 2)  # map distance relative to origin    #u,v = lidar_to_surround_coords(x,y,z,d)    u,v = lidar_to_surround_coords_360(x,y,z,d)    width  = int(SURROUND_U_MAX - SURROUND_U_MIN + 1)    height = int(SURROUND_V_MAX - SURROUND_V_MIN + 1)    surround     = np.zeros((height, width, 3), dtype=np.float32)    surround_img = np.zeros((height, width, 3), dtype=np.uint8)    surround[v, u, 0] = d    surround[v, u, 1] = z    surround[v, u, 2] = r    surround_img[v, u, 0] = normalise_to_255(np.clip(d,     0, 30))    surround_img[v, u, 1] = normalise_to_255(np.clip(z+1.8, 0, 100))    surround_img[v, u, 2] = normalise_to_255(np.clip(r,     0, 30))    return surround, surround_img    In&amp;nbsp;[6]:    # drawing ####def box3d_to_surround_box(boxes3d):    is_reshape = boxes3d.shape==(8,3) #support for single box3d    if is_reshape:        boxes3d = boxes3d.reshape(1,8,3)    num = len(boxes3d)    surround_boxes = np.zeros((num,4),  dtype=np.float32)    for n in range(num):        b = boxes3d[n]        x = b[:,0]        y = b[:,1]        z = b[:,2]        d = np.sqrt(x ** 2 + y ** 2)        u,v = lidar_to_surround_coords(x,y,z,d)        umin,umax = np.min(u),np.max(u)        vmin,vmax = np.min(v),np.max(v)        surround_boxes[n] = np.array([umin,vmin,umax,vmax])    if is_reshape:        surround_boxes = surround_boxes.squeeze()    return surround_boxes    In&amp;nbsp;[7]:    def draw_box3d_on_surround(image, boxes3d, color=(255,255,255)):    surround_boxes = box3d_to_surround_box(boxes3d)    is_reshape = surround_boxes.shape==(4)    if is_reshape:        surround_boxes = surround_boxes.reshape(1,4)    num = len(surround_boxes)    for n in range(num):        b = surround_boxes[n]        x1,y1,x2,y2  = b        cv2.rectangle(image,(x1,y1),(x2,y2),color,1,cv2.LINE_AA)    In&amp;nbsp;[9]:    lidar_dir = &amp;#39;./npy&amp;#39;    In&amp;nbsp;[13]:    lidar_file = &amp;#39;./npy/1530509312596502000.npy&amp;#39;    In&amp;nbsp;[14]:    lidar = np.load(lidar_file)    In&amp;nbsp;[16]:    type(lidar)        Out[16]:numpy.ndarrayIn&amp;nbsp;[17]:    surround, surround_img = lidar_to_surround(lidar)    In&amp;nbsp;[18]:    surround_img_file = &amp;#39;1530509312596502000.png&amp;#39;    In&amp;nbsp;[24]:    cv2.imwrite(surround_img_file,surround_img)        Out[24]:TrueIn&amp;nbsp;[20]:    !ls -l        total 36-rw-r--r-- 1 root     root     6516 Dec  3 06:46 1530509312596502000.png-rw-r--r-- 1 root     root     1472 Dec  3 06:38 Untitled.ipynb-rw-rw-r-- 1 adioshun adioshun    0 Dec  3 06:17 main.pydrwxr-xr-x 2 root     root     4096 Dec  3 06:42 npy-rw-rw-r-- 1 adioshun adioshun 4173 Dec  3 06:42 run_dump_lidar.py-rw-r--r-- 1 root     root     7235 Dec  3 06:46 surround_view.ipynbIn&amp;nbsp;[25]:    from IPython.display import ImageImage(filename=&amp;#39;1530509312596502000.png&amp;#39;)        Out[25]:In&amp;nbsp;[3]:    !jupyter nbconvert --to html --template basic surround_view.ipynb        [NbConvertApp] Converting notebook surround_view.ipynb to html[NbConvertApp] Writing 39162 bytes to surround_view.htmlIn&amp;nbsp;[4]:    !jupyter nbconvert --to html surround_view.ipynb        [NbConvertApp] Converting notebook surround_view.ipynb to html[NbConvertApp] Writing 312481 bytes to surround_view.htmlIn&amp;nbsp;[&amp;nbsp;]:                      			  	    Back to main site: www.frankcleary.com	  	            &amp;lt;/html&amp;gt;",
    "url": "http://localhost:4000/docs/surround_view/",
    "relUrl": "/docs/surround_view/"
  }
}
